{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of DL_CW3_allmodels.ipynb","provenance":[{"file_id":"1rfyyVllhdAwI4wmVK-jKDMnp4j_iYICs","timestamp":1620590481588}],"collapsed_sections":[],"authorship_tag":"ABX9TyPhoHMbS1uX2NWKjI5GIFBJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Q3w5EK2WV4Dz","executionInfo":{"status":"ok","timestamp":1620466910101,"user_tz":-60,"elapsed":4637,"user":{"displayName":"abhinav gyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiU5rB7xwgv8Whhs10EEH-bIaZ0sJhfm9669VIC=s64","userId":"11401909896438186779"}}},"source":["import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision.models import resnet50\n","from torchvision.models import googlenet"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wWBa_7zttpbK"},"source":["# MNIST Dataset Setup"]},{"cell_type":"code","metadata":{"id":"ULlT93quWAS8"},"source":["\"\"\"Downloading the MNIST dataset\"\"\"\n","\n","train_loader = torch.utils.data.DataLoader( torchvision.datasets.MNIST('/files/', train=True, download=True,\n","                             transform=torchvision.transforms.Compose([\n","                               torchvision.transforms.ToTensor(),\n","                               torchvision.transforms.Normalize((0.1307,), (0.3081,))])),\n","                            batch_size=batch_size_train, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('/files/', train=False, download=True,\n","                             transform=torchvision.transforms.Compose([\n","                               torchvision.transforms.ToTensor(),\n","                               torchvision.transforms.Normalize(\n","                                 (0.1307,), (0.3081,))])),\n","                            batch_size=batch_size_test, shuffle=True)\n","\n","examples = enumerate(test_loader)\n","batch_idx, (example_data, example_targets) = next(examples)\n","\n","example_data.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PuOEeg56WC2T"},"source":["\"\"\"Visualizing some of the ground truth image.\"\"\"\n","\n","import matplotlib.pyplot as plt\n","fig = plt.figure()\n","for i in range(6):\n","  plt.subplot(2,3,i+1)\n","  plt.tight_layout()\n","  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n","  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n","  plt.xticks([])\n","  plt.yticks([])\n","fig"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HItVJ3JxtwSb"},"source":["#ResNet"]},{"cell_type":"code","metadata":{"id":"FmPNuBHGV2Do"},"source":["\"\"\"Initialize the training and testing parameters.\"\"\"\n","\n","n_epochs = 5\n","batch_size_train = 64\n","batch_size_test = 1000\n","learning_rate = 0.01\n","momentum = 0.5\n","log_interval = 10\n","\n","random_seed = 1\n","torch.backends.cudnn.enabled = True\n","torch.manual_seed(random_seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v68qGQsHWK9T","executionInfo":{"status":"ok","timestamp":1620467032792,"user_tz":-60,"elapsed":11813,"user":{"displayName":"abhinav gyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiU5rB7xwgv8Whhs10EEH-bIaZ0sJhfm9669VIC=s64","userId":"11401909896438186779"}}},"source":["\"\"\"Initializing model with output for 10 classes and converting model to accept \"\"\"\n","\n","model = resnet50(num_classes=10)  #number of classes in MNIST is 10. This modifies the output features of the last FC layer.\n","#changing to single channel\n","model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","\n","#Using SGD optimizer with LR=0.01 and Momentum=0.5\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n","#optimizer = optim.Adam(model.parameters(), lr=0.01)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","#exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n","\n","if torch.cuda.is_available():\n","    model = model.cuda()      #push the parameters to default device.\n","    criterion = criterion.cuda()\n","\n","train_losses = []\n","train_counter = []\n","test_losses = []\n","test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n","test_acc1 = []\n","\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"pNxLMzbJWSME","executionInfo":{"status":"ok","timestamp":1620467040137,"user_tz":-60,"elapsed":960,"user":{"displayName":"abhinav gyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiU5rB7xwgv8Whhs10EEH-bIaZ0sJhfm9669VIC=s64","userId":"11401909896438186779"}}},"source":["\"\"\"Training model function\"\"\"\n","\n","def train(epoch):\n","  model.train()\n","\n","  for batch_idx, (data, target) in enumerate(train_loader):\n","    #if GPU is available, move data and target to GPU\n","    if torch.cuda.is_available():\n","      data=data.cuda()\n","      target=target.cuda()\n","    \n","    #compute output and loss.    \n","    output = model(data)\n","    loss = criterion(output, target)\n","\n","    #backward and update model.\n","\n","    #In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n","    #This is convenient while training RNNs. So, the default action is to accumulate (i.e. sum) the gradients on every loss.backward() call.\n","    #Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n","    #Else the gradient would point in some other direction than the intended direction towards the minimum (or maximum, in case of maximization objectives).\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if batch_idx % log_interval == 0:\n","      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","        epoch, batch_idx * len(data), len(train_loader.dataset),\n","        100. * batch_idx / len(train_loader), loss.item()))\n","      \n","      train_losses.append(loss.item())\n","      train_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n","\n","      torch.save(model.state_dict(), '/resnetmodel.pth')\n","      torch.save(optimizer.state_dict(), '/optimizer.pth')\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"aFTRrNIJq2L2"},"source":["\"\"\"Testing model function\"\"\"\n","def test():\n","  model.eval()\n","  test_loss = 0\n","  correct = 0\n","\n","  with torch.no_grad():\n","    for data, target in test_loader:\n","      if torch.cuda.is_available():\n","        data=data.cuda()\n","        target=target.cuda()\n","\n","      output = model(data)\n","      test_loss += criterion(output, target).item()\n","\n","      pred = output.data.max(1, keepdim=True)[1]\n","      correct += pred.eq(target.data.view_as(pred)).sum()\n","\n","  test_loss /= len(test_loader.dataset)\n","  test_losses.append(test_loss)\n","  test_acc = 100 * correct / len(test_loader.dataset)\n","  test_acc1.append(test_acc)\n","\n","  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","    test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Utckaa_6WVGz"},"source":["\"\"\"Training and testing results at each epoch\"\"\"\n","\n","epochs=[]\n","for epoch in range(1, n_epochs + 1):\n","  train(epoch)\n","  test()\n","  epochs.append(epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3ZlOlGag7Re"},"source":["\"\"\"Ploting loss curve \"\"\"\n","\n","fig = plt.figure()\n","plt.plot(train_counter, train_losses, color='blue')\n","plt.legend(['Train Loss'], loc='upper right')\n","plt.xlabel('number of training examples seen')\n","plt.ylabel('loss')\n","fig"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BeOrvwadg9oI"},"source":["\"\"\"Plotting accuracy curve\"\"\"\n","\n","fig = plt.figure()\n","plt.plot(epochs, test_acc1, color='blue')\n","plt.legend(['Train Accuracy'], loc='upper right')\n","plt.xlabel('number of epochs')\n","plt.ylabel('Accuracy %')\n","fig"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K-88PtCqWahL"},"source":["\"\"\"Visualizing predictions\"\"\"\n","\n","with torch.no_grad():\n","  example_data=example_data.cuda()\n","  output = model(example_data)\n","\n","fig = plt.figure()\n","for i in range(6):\n","  plt.subplot(2,3,i+1)\n","  plt.tight_layout()\n","  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n","  plt.title(\"Prediction: {}\".format(\n","    output.data.max(1, keepdim=True)[1][i].item()))\n","  plt.xticks([])\n","  plt.yticks([])\n","fig"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qocd5OLfWfAT","executionInfo":{"status":"ok","timestamp":1620469372825,"user_tz":-60,"elapsed":80420,"user":{"displayName":"abhinav gyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiU5rB7xwgv8Whhs10EEH-bIaZ0sJhfm9669VIC=s64","userId":"11401909896438186779"}},"outputId":"412c068e-24a6-4a7e-afde-2d1fb2f16a21"},"source":["\"\"\"### GoogleNet\"\"\"\n","\n","model2 = googlenet(num_classes=10)\n","model2.conv1.conv = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","model2=model2.cuda()\n","\n","optimizer = optim.SGD(model2.parameters(), lr=learning_rate,\n","                      momentum=momentum)\n","\n","train_losses2 = []\n","train_counter2 = []\n","test_losses2 = []\n","test_counter2 = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n","test_acc2 = []"],"execution_count":10,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/googlenet.py:79: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n","  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"dkBsgwMkWixG","executionInfo":{"status":"ok","timestamp":1620469389182,"user_tz":-60,"elapsed":457,"user":{"displayName":"abhinav gyani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiU5rB7xwgv8Whhs10EEH-bIaZ0sJhfm9669VIC=s64","userId":"11401909896438186779"}}},"source":["\"\"\"Training function\"\"\"\n","\n","def train(epoch):\n","  model2.train()\n","  for batch_idx, (data, target) in enumerate(train_loader):\n","    optimizer.zero_grad()\n","    data=data.cuda()\n","    target=target.cuda()\n","    output = model2(data)\n","    loss = criterion(output.logits, target)\n","    loss.backward()\n","    optimizer.step()\n","    if batch_idx % log_interval == 0:\n","      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","        epoch, batch_idx * len(data), len(train_loader.dataset),\n","        100. * batch_idx / len(train_loader), loss.item()))\n","      train_losses2.append(loss.item())\n","      train_counter2.append(\n","        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n","      torch.save(model2.state_dict(), '/googlenetmodel.pth')\n","      torch.save(optimizer.state_dict(), '/optimizer.pth')\n","\n","\"\"\"Testing function\"\"\"\n","\n","def test():\n","  model2.eval()\n","  test_loss = 0\n","  correct = 0\n","  with torch.no_grad():\n","    for data, target in test_loader:\n","      data=data.cuda()\n","      target=target.cuda()\n","      output = model2(data)\n","      test_loss += criterion(output, target).item()\n","      pred = output.data.max(1, keepdim=True)[1]\n","      correct += pred.eq(target.data.view_as(pred)).sum()\n","  test_loss /= len(test_loader.dataset)\n","  test_losses2.append(test_loss)\n","  test_acc = 100 * correct / len(test_loader.dataset)\n","  test_acc2.append(test_acc)\n","  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","    test_loss, correct, len(test_loader.dataset),\n","    100. * correct / len(test_loader.dataset)))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"C3W8LBK2hEHC"},"source":["\"\"\"Visualizing loss and accuracy at each epoch\"\"\"\n","\n","epochs=[]\n","for epoch in range(1, n_epochs + 1):\n","  train(epoch)\n","  test()\n","  epochs.append(epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_XLDBZjhF2P"},"source":["\"\"\"Plotting training loss\"\"\"\n","\n","fig = plt.figure()\n","plt.plot(train_counter2, train_losses2, color='blue')\n","plt.plot(train_counter2, train_losses, color='green')\n","plt.legend(['GoogleNet Train Loss','ResNet50 Train Loss' ], loc='upper right')\n","plt.xlabel('number of training examples seen')\n","plt.ylabel('loss')\n","fig"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"haWwiewIhI8i"},"source":["\"\"\"Plotting testing accuracy\"\"\"\n","\n","fig = plt.figure()\n","plt.plot(epochs, test_acc1, color='blue')\n","plt.plot(epochs, test_acc2, color='green')\n","plt.legend(['Test Accuracy (ResNet50)','Test Accuracy (GoogleNet)'], loc='lower right')\n","plt.xlabel('number of epochs')\n","plt.ylabel('Accuracy %')\n","fig"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T7wPqx10VvDt"},"source":["\"\"\"Visualizing predicted data\"\"\"\n","\n","with torch.no_grad():\n","  example_data = example_data.cuda()\n","  output = model(example_data)\n","\n","fig = plt.figure()\n","for i in range(6):\n","  plt.subplot(2,3,i+1)\n","  plt.tight_layout()\n","  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n","  plt.title(\"Prediction: {}\".format(\n","    output.data.max(1, keepdim=True)[1][i].item()))\n","  plt.xticks([])\n","  plt.yticks([])\n","fig"],"execution_count":null,"outputs":[]}]}