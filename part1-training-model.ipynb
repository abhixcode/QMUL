{"nbformat":4,"nbformat_minor":0,"metadata":{"authors":[{"name":"maxluk"}],"microsoft":{"host":{"AzureML":{"notebookHasBeenCompleted":true}}},"network_required":false,"kernel_info":{"name":"python3-azureml"},"msauthor":"roastala","language_info":{"name":"python","version":"3.6.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3-azureml","language":"python","display_name":"Python 3.6 - AzureML"},"categories":["tutorials","image-classification-mnist-data"],"nteract":{"version":"nteract-front-end@1.0.0"},"colab":{"name":"part1-training-model.ipynb","provenance":[{"file_id":"1P8_2b7ZyrhD3MYVpEDIKAmeA6a5N5no0","timestamp":1629347091527}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"0i_bu4qToZJG"},"source":["Import all the necessary Python packages"]},{"cell_type":"code","metadata":{"tags":["check version"],"gather":{"logged":1625654427552},"id":"ysWruTafpdsb"},"source":["%matplotlib inline\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import azureml.core\n","from azureml.core import Workspace\n","\n","# check core SDK version number\n","print(\"Azure ML SDK Version: \", azureml.core.VERSION)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kyIJ8SBGooWE"},"source":["We create an Azure workspace object. A workspace is more like a collection of resources. We read the workspace name from a configuration file stored on the compute."]},{"cell_type":"code","metadata":{"tags":["load workspace"],"gather":{"logged":1625654431710},"id":"c-BMsYYVpdsh"},"source":["# load workspace configuration from the config.json file in the current folder.\n","ws = Workspace.from_config()\n","print(ws.name, ws.location, ws.resource_group, sep='\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AjZ_y6Xbo7vn"},"source":["We create an experiment to track different runs of the same model or service. A single workspace can have multiple experiments."]},{"cell_type":"code","metadata":{"tags":["create experiment"],"gather":{"logged":1625654435000},"id":"ksaaeYADpdsm"},"source":["experiment_name = 'diabetes-sklearn'\n","\n","from azureml.core import Experiment\n","exp = Experiment(workspace=ws, name=experiment_name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WXStGNsppZxd"},"source":["We run our experiments on Azure's cluster of virtual machines. The below code checks if the given compute cluster exists - if yes then uses it for execution otherwise a new compute cluster is created."]},{"cell_type":"code","metadata":{"tags":["create mlc","amlcompute"],"gather":{"logged":1625654439072},"id":"tahRb-Khpdsr"},"source":["from azureml.core.compute import AmlCompute\n","from azureml.core.compute import ComputeTarget\n","import os\n","\n","# choose a name for your cluster\n","compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpu-cluster-agx\")\n","compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n","compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n","\n","# This code uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n","vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n","\n","\n","if compute_name in ws.compute_targets:\n","    compute_target = ws.compute_targets[compute_name]\n","    if compute_target and type(compute_target) is AmlCompute:\n","        print(\"found compute target: \" + compute_name)\n","else:\n","    print(\"creating new compute target...\")\n","    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n","                                                                min_nodes = compute_min_nodes, \n","                                                                max_nodes = compute_max_nodes)\n","\n","    # create the cluster\n","    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n","    \n","    # can poll for a minimum number of nodes and for a specific timeout. \n","    # if no min node count is provided it will use the scale settings for the cluster\n","    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n","    \n","     # For a more detailed view of current AmlCompute status, use get_status()\n","    print(compute_target.get_status().serialize())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"gather":{"logged":1625654443222},"id":"pcQEeT9fpdsv"},"source":["import os\n","script_folder = os.path.join(os.getcwd(), \"diabetes-sklearn\")\n","os.makedirs(script_folder, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RlBeSTcHpdsx"},"source":["%%writefile $script_folder/train.py\n","\n","import argparse\n","import os\n","import numpy as np\n","import glob\n","import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import LinearRegression\n","import joblib\n","\n","from azureml.core import Run\n","\n","parser = argparse.ArgumentParser()\n","args = parser.parse_args()\n","\n","# load train and test set into numpy arrays\n","data = pd.read_csv(\"diabetes.csv\")\n","print(data.shape)\n","feature_names = data.iloc[:,0:8].columns\n","target_name = data.iloc[:1,8:].columns\n","data_features = data[feature_names]\n","data_target = data[target_name]\n","print(feature_names)\n","print(target_name)\n","\n","from sklearn.model_selection import train_test_split\n","np.random.seed(123)\n","X_train, X_test, y_train, y_test = train_test_split(data_features.to_numpy(dtype=np.uint8), data_target.to_numpy(dtype=np.uint8), train_size = 0.70, test_size = 0.30, random_state = 1)\n","y_train = y_train.reshape(-1)\n","y_test = y_test.reshape(-1)\n","\n","print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep = '\\n')\n","\n","# get hold of the current run\n","run = Run.get_context()\n","\n","print('Train a linear regression model')\n","clf = LinearRegression()\n","clf.fit(X_train, y_train)\n","\n","print(clf.coef_)\n","print(clf.intercept_)\n","\n","print('Predict the test set with size = ', X_test.shape)\n","y_hat = clf.predict(X_test)\n","print(y_hat)\n","y_classify = lambda k: 1 * (k > 0.5)\n","y_hat = y_classify(y_hat)\n","print(y_hat)\n","\n","# calculate accuracy on the prediction\n","acc = np.average(y_hat == y_test)\n","print('Accuracy is', acc)\n","\n","#run.log('regularization rate', np.float(args.reg))\n","run.log('accuracy', np.float(acc))\n","\n","os.makedirs('outputs', exist_ok=True)\n","# note file saved in the outputs folder is automatically uploaded into experiment record\n","joblib.dump(value=clf, filename='outputs/diabetes-sklearn-model.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"gather":{"logged":1625654823650},"id":"26f0BeAVpds0"},"source":["from azureml.core.environment import Environment\n","from azureml.core.conda_dependencies import CondaDependencies\n","\n","# to install required packages\n","env = Environment('diabetes-env')\n","cd = CondaDependencies.create(pip_packages=['azureml-dataset-runtime[pandas,fuse]', 'azureml-defaults'], conda_packages = ['scikit-learn==0.22.1'])\n","\n","env.python.conda_dependencies = cd\n","\n","# Register environment to re-use later\n","env.register(workspace = ws)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fc0kfKBGQlYZ"},"source":["A ScriptRunConfig object is created to specify the configuration of training job, environment and compute to use."]},{"cell_type":"code","metadata":{"tags":["configure estimator"],"gather":{"logged":1625654829009},"id":"2Up83JBrpds1"},"source":["from azureml.core import ScriptRunConfig\n","\n","#args = ['--regularization', 0.5]\n","args = []\n","\n","src = ScriptRunConfig(source_directory=script_folder,\n","                      script='train.py', \n","                      arguments=args,\n","                      compute_target=compute_target,\n","                      environment=env)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NfLlNzvsRQ6l"},"source":["Once everything is configured, we submit the job to the cluster."]},{"cell_type":"code","metadata":{"tags":["remote run","amlcompute","scikit-learn"],"gather":{"logged":1625654835084},"id":"65VheS8Lpds3"},"source":["run = exp.submit(config=src)\n","run"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":["use notebook widget"],"gather":{"logged":1625611723804},"id":"fQmsoWuwpds4"},"source":["from azureml.widgets import RunDetails\n","RunDetails(run).show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":["remote run","amlcompute","scikit-learn"],"gather":{"logged":1625611735131},"id":"nLBtK5bGpds5"},"source":["# specify show_output to True for a verbose log\n","run.wait_for_completion(show_output=True) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":["get metrics"],"gather":{"logged":1625655614956},"id":"xgbX6wHFpds6"},"source":["print(run.get_metrics())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":["query history"],"gather":{"logged":1625655618534},"id":"SXNCgpckpds7"},"source":["print(run.get_file_names())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":["register model from history"],"gather":{"logged":1625655622943},"id":"WQh-Xtu9pds8"},"source":["# register model \n","model = run.register_model(model_name='diabetes_sklearn', model_path='outputs/diabetes-sklearn-model.pkl')\n","print(model.name, model.id, model.version, sep='\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TOduUkGqpds9"},"source":["![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/tutorials/img-classification-part1-training.png)"]}]}